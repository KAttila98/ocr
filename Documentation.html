<!DOCTYPE html>
<html>
<head>
<title>Documentation.md</title>
<meta http-equiv="Content-type" content="text/html;charset=UTF-8">

<style>
/* https://github.com/microsoft/vscode/blob/master/extensions/markdown-language-features/media/markdown.css */
/*---------------------------------------------------------------------------------------------
 *  Copyright (c) Microsoft Corporation. All rights reserved.
 *  Licensed under the MIT License. See License.txt in the project root for license information.
 *--------------------------------------------------------------------------------------------*/

body {
	font-family: var(--vscode-markdown-font-family, -apple-system, BlinkMacSystemFont, "Segoe WPC", "Segoe UI", "Ubuntu", "Droid Sans", sans-serif);
	font-size: var(--vscode-markdown-font-size, 14px);
	padding: 0 26px;
	line-height: var(--vscode-markdown-line-height, 22px);
	word-wrap: break-word;
}

#code-csp-warning {
	position: fixed;
	top: 0;
	right: 0;
	color: white;
	margin: 16px;
	text-align: center;
	font-size: 12px;
	font-family: sans-serif;
	background-color:#444444;
	cursor: pointer;
	padding: 6px;
	box-shadow: 1px 1px 1px rgba(0,0,0,.25);
}

#code-csp-warning:hover {
	text-decoration: none;
	background-color:#007acc;
	box-shadow: 2px 2px 2px rgba(0,0,0,.25);
}

body.scrollBeyondLastLine {
	margin-bottom: calc(100vh - 22px);
}

body.showEditorSelection .code-line {
	position: relative;
}

body.showEditorSelection .code-active-line:before,
body.showEditorSelection .code-line:hover:before {
	content: "";
	display: block;
	position: absolute;
	top: 0;
	left: -12px;
	height: 100%;
}

body.showEditorSelection li.code-active-line:before,
body.showEditorSelection li.code-line:hover:before {
	left: -30px;
}

.vscode-light.showEditorSelection .code-active-line:before {
	border-left: 3px solid rgba(0, 0, 0, 0.15);
}

.vscode-light.showEditorSelection .code-line:hover:before {
	border-left: 3px solid rgba(0, 0, 0, 0.40);
}

.vscode-light.showEditorSelection .code-line .code-line:hover:before {
	border-left: none;
}

.vscode-dark.showEditorSelection .code-active-line:before {
	border-left: 3px solid rgba(255, 255, 255, 0.4);
}

.vscode-dark.showEditorSelection .code-line:hover:before {
	border-left: 3px solid rgba(255, 255, 255, 0.60);
}

.vscode-dark.showEditorSelection .code-line .code-line:hover:before {
	border-left: none;
}

.vscode-high-contrast.showEditorSelection .code-active-line:before {
	border-left: 3px solid rgba(255, 160, 0, 0.7);
}

.vscode-high-contrast.showEditorSelection .code-line:hover:before {
	border-left: 3px solid rgba(255, 160, 0, 1);
}

.vscode-high-contrast.showEditorSelection .code-line .code-line:hover:before {
	border-left: none;
}

img {
	max-width: 100%;
	max-height: 100%;
}

a {
	text-decoration: none;
}

a:hover {
	text-decoration: underline;
}

a:focus,
input:focus,
select:focus,
textarea:focus {
	outline: 1px solid -webkit-focus-ring-color;
	outline-offset: -1px;
}

hr {
	border: 0;
	height: 2px;
	border-bottom: 2px solid;
}

h1 {
	padding-bottom: 0.3em;
	line-height: 1.2;
	border-bottom-width: 1px;
	border-bottom-style: solid;
}

h1, h2, h3 {
	font-weight: normal;
}

table {
	border-collapse: collapse;
}

table > thead > tr > th {
	text-align: left;
	border-bottom: 1px solid;
}

table > thead > tr > th,
table > thead > tr > td,
table > tbody > tr > th,
table > tbody > tr > td {
	padding: 5px 10px;
}

table > tbody > tr + tr > td {
	border-top: 1px solid;
}

blockquote {
	margin: 0 7px 0 5px;
	padding: 0 16px 0 10px;
	border-left-width: 5px;
	border-left-style: solid;
}

code {
	font-family: Menlo, Monaco, Consolas, "Droid Sans Mono", "Courier New", monospace, "Droid Sans Fallback";
	font-size: 1em;
	line-height: 1.357em;
}

body.wordWrap pre {
	white-space: pre-wrap;
}

pre:not(.hljs),
pre.hljs code > div {
	padding: 16px;
	border-radius: 3px;
	overflow: auto;
}

pre code {
	color: var(--vscode-editor-foreground);
	tab-size: 4;
}

/** Theming */

.vscode-light pre {
	background-color: rgba(220, 220, 220, 0.4);
}

.vscode-dark pre {
	background-color: rgba(10, 10, 10, 0.4);
}

.vscode-high-contrast pre {
	background-color: rgb(0, 0, 0);
}

.vscode-high-contrast h1 {
	border-color: rgb(0, 0, 0);
}

.vscode-light table > thead > tr > th {
	border-color: rgba(0, 0, 0, 0.69);
}

.vscode-dark table > thead > tr > th {
	border-color: rgba(255, 255, 255, 0.69);
}

.vscode-light h1,
.vscode-light hr,
.vscode-light table > tbody > tr + tr > td {
	border-color: rgba(0, 0, 0, 0.18);
}

.vscode-dark h1,
.vscode-dark hr,
.vscode-dark table > tbody > tr + tr > td {
	border-color: rgba(255, 255, 255, 0.18);
}

</style>

<style>
/* Tomorrow Theme */
/* http://jmblog.github.com/color-themes-for-google-code-highlightjs */
/* Original theme - https://github.com/chriskempson/tomorrow-theme */

/* Tomorrow Comment */
.hljs-comment,
.hljs-quote {
	color: #8e908c;
}

/* Tomorrow Red */
.hljs-variable,
.hljs-template-variable,
.hljs-tag,
.hljs-name,
.hljs-selector-id,
.hljs-selector-class,
.hljs-regexp,
.hljs-deletion {
	color: #c82829;
}

/* Tomorrow Orange */
.hljs-number,
.hljs-built_in,
.hljs-builtin-name,
.hljs-literal,
.hljs-type,
.hljs-params,
.hljs-meta,
.hljs-link {
	color: #f5871f;
}

/* Tomorrow Yellow */
.hljs-attribute {
	color: #eab700;
}

/* Tomorrow Green */
.hljs-string,
.hljs-symbol,
.hljs-bullet,
.hljs-addition {
	color: #718c00;
}

/* Tomorrow Blue */
.hljs-title,
.hljs-section {
	color: #4271ae;
}

/* Tomorrow Purple */
.hljs-keyword,
.hljs-selector-tag {
	color: #8959a8;
}

.hljs {
	display: block;
	overflow-x: auto;
	color: #4d4d4c;
	padding: 0.5em;
}

.hljs-emphasis {
	font-style: italic;
}

.hljs-strong {
	font-weight: bold;
}
</style>

<style>
/*
 * Markdown PDF CSS
 */

 body {
	font-family: -apple-system, BlinkMacSystemFont, "Segoe WPC", "Segoe UI", "Ubuntu", "Droid Sans", sans-serif, "Meiryo";
	padding: 0 12px;
}

pre {
	background-color: #f8f8f8;
	border: 1px solid #cccccc;
	border-radius: 3px;
	overflow-x: auto;
	white-space: pre-wrap;
	overflow-wrap: break-word;
}

pre:not(.hljs) {
	padding: 23px;
	line-height: 19px;
}

blockquote {
	background: rgba(127, 127, 127, 0.1);
	border-color: rgba(0, 122, 204, 0.5);
}

.emoji {
	height: 1.4em;
}

code {
	font-size: 14px;
	line-height: 19px;
}

/* for inline code */
:not(pre):not(.hljs) > code {
	color: #C9AE75; /* Change the old color so it seems less like an error */
	font-size: inherit;
}

/* Page Break : use <div class="page"/> to insert page break
-------------------------------------------------------- */
.page {
	page-break-after: always;
}

</style>

<script src="https://unpkg.com/mermaid/dist/mermaid.min.js"></script>
</head>
<body>
  <script>
    mermaid.initialize({
      startOnLoad: true,
      theme: document.body.classList.contains('vscode-dark') || document.body.classList.contains('vscode-high-contrast')
          ? 'dark'
          : 'default'
    });
  </script>
<h1 id="engineering-documentation">Engineering Documentation</h1>
<h2 id="project-goal">Project Goal</h2>
<p>The goal of this project is to extract text and related information (e.g., position) from screenshots of the Archicad software.</p>
<h2 id="implemented-component-description">Implemented Component Description</h2>
<h3 id="core-algorithm">Core Algorithm</h3>
<p>The implemented component utilizes the latest version of the Tesseract OCR engine. The core algorithm includes a line-finding algorithm and an LSTM-based text classifier. Tesseract is chosen for its high performance, low computational complexity, and ease of implementation.</p>
<p>Tesseract generally performs well on images containing printed texts, but its efficiency significantly drops when there are texts with various orientation on one image or the text-background color contrast is not high enough or the image quality is bad (The provided test set contains plenty of these cases). Therefore simply applying Tesseract would not bring the desired results, I had to extend it with further steps. A high-level description of the steps carried out by the implemented component can be seen on the flowchart below:</p>
<p><img src="docs/images/flowchart_reorg.png" alt="Flowchart"></p>
<h3 id="preprocessing-steps">Preprocessing Steps</h3>
<p>For each input image, the component performs preprocessing steps (ideas are based on the Tesseract documentation <a href="https://tesseract-ocr.github.io/tessdoc/ImproveQuality">ImproveQuality</a>). These steps include upscaling (based on user-defined parameter), denoising, converting to grayscale, and applying OpenCV thresholding (OTSU or Adaptive). The effect of these steps can be seen on the example below:</p>
<table>
<thead>
<tr>
<th>Before preprocessing</th>
<th>After preprocessing</th>
</tr>
</thead>
<tbody>
<tr>
<td><img src="docs/images/S004_SL_check_placeHolder_ref.png" alt="Before preprocessing"></td>
<td><img src="docs/images/denoising.png" alt="After preprocessing"></td>
</tr>
</tbody>
</table>
<p>Additional preprocessing is applied for images with a dark background, where the algorithm highlights the blue color (determined from HSV format of the images).</p>
<h4 id="example">Example:</h4>
<table>
<thead>
<tr>
<th>Before preprocessing</th>
<th>After preprocessing</th>
</tr>
</thead>
<tbody>
<tr>
<td><img src="docs/images/TCS003_TXTLOrient_ObjBlocks_imageDumpCheck_ref.png" alt="Before preprocessing"></td>
<td><img src="docs/images/dark.png" alt="After preprocessing"></td>
</tr>
</tbody>
</table>
<p>Note that in case of images with low text-background contrast Adaptive threshold performs better than OTSU, so I recommend using that one.</p>
<h3 id="text-orientation-handling">Text Orientation Handling</h3>
<p>To address Tesseract's limitations in processing text with various orientations, the following steps are taken:</p>
<ol>
<li>The user defines a range of angles in degrees.</li>
<li>For each angle in the defined range:
<ul>
<li>Rotate the image.</li>
<li>Apply Tesseract on the rotated image.</li>
<li>Collect prediction results for all angles.</li>
<li>Transform results back to the original image coordinate system.</li>
</ul>
</li>
<li>Non-Maximal Suppression is performed to eliminate double detections caused by processing the image at different angles.</li>
</ol>
<h3 id="evaluation">Evaluation</h3>
<p>Manual evaluation of the component was performed on a set of 10 images with diverse features. The optimal hyperparameter settings determined from this evaluation are:</p>
<ul>
<li>confidence_threshold: 80</li>
<li>rotation_range: (-45, 45, 5)</li>
<li>apply_denoising: True</li>
<li>thresholding_ethod: adaptive</li>
<li>image_upscale_factor: 2</li>
</ul>
<h3 id="computational-complexity">Computational complexity</h3>
<p>The inputs of the component is an image with dimensions W x H x 3. Let A be the number of different rotation angles applyied during execution. In this case the computational complexity of the component is:  <strong>O(W x H x A)</strong>, where <strong>A</strong> is considered as a constant hyper-parameter.</p>
<h3 id="output">Output</h3>
<p>The script saves exported text, including position and rotation angle, in a .txt file under the specified folder (text_output_folder_path). Example output:</p>
<pre class="hljs"><code><div>Found text: 200; Center position (in pixels): (818,539); Dimension (width, height): (30,16); Orientation (degrees): -25
Found text: 250; Center position (in pixels): (705,549); Dimension (width, height): (18,31); Orientation (degrees): 10
...
</div></code></pre>
<p>If <code>--save_visualization</code> is used, images with bounding boxes indicating recognized text are saved. Example:</p>
<p><img src="docs/images/TCS001_TXTLOrient_Explode_Leaders_Archicad_ref.png" alt="Visual output"></p>
<h2 id="setup-guide">Setup Guide</h2>
<h3 id="required-python-modules">Required Python Modules</h3>
<ul>
<li><code>pytesseract==0.3.10</code></li>
<li><code>tqdm==4.62.2</code></li>
<li><code>numpy==1.23.5</code></li>
<li><code>opencv-python==4.7.0.68</code></li>
<li><code>matplotlib==3.4.3</code></li>
<li><code>nms==0.1.6</code></li>
</ul>
<p>Requirements are included in <code>requirements.txt</code>.</p>
<h3 id="additional-steps-when-using-the-component-on-windows">Additional steps when using the component on Windows</h3>
<ol>
<li>Install the Tesseract engine <a href="https://digi.bib.uni-mannheim.de/tesseract/tesseract-ocr-w64-setup-5.3.3.20231005.exe">here</a>.</li>
<li>Add the Tesseract path to <code>--tesseract_exe_path</code> when running <code>ocr_script.py</code>.</li>
</ol>
<h3 id="usage">Usage</h3>
<p>Run the component using <code>ocr_script.py</code></p>
<h2 id="user-manual">User Manual</h2>
<p>The script has the following arguments:</p>
<h3 id="arguments">Arguments</h3>
<ul>
<li><code>--image_folder_path</code>: Path to the folder containing input images (required).</li>
<li><code>--tesseract_exe_path</code>: Path to the Tesseract engine (required on Windows).</li>
<li><code>--image_upscale_factor</code>: Integer value &gt; 1 for upscaling low-resolution images (default 2).</li>
<li><code>--apply_denoising</code>: Apply OpenCV denoising algorithm (True/False).</li>
<li><code>--thresholding_method</code>: Thresholding algorithm (default None).</li>
<li><code>--confidence_threshold</code>: Confidence threshold for predictions (default 80).</li>
<li><code>--rotation_range</code>: Range of image rotation angles (from_angle to_angle step_size).</li>
<li><code>--text_output_folder_path</code>: Path to folder for saving extracted text in .txt files (default).</li>
<li><code>--save_visualizations</code>: Save visualizations with highlighted text (optional).</li>
<li><code>--visualization_folder_path</code>: Path to folder for saving visualizations (if desired).</li>
</ul>
<h3 id="example-command">Example Command</h3>
<pre class="hljs"><code><div>python ocr_script.py --image_folder_path testfiles --tesseract_exe_path &quot;C:\\Program Files\\Tesseract-OCR\\tesseract.exe&quot; --confidence_threshold 80 --rotation_range -45 45 5 --apply_denoising --thresholding_method adaptive --image_upscale_factor 2 --save_visualizations
</div></code></pre>

</body>
</html>
